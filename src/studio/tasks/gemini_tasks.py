import base64
import json
import tempfile
import time
from pathlib import Path
from typing import Tuple, Optional

import OpenImageIO as oiio
import numpy as np
import requests

from .task import Task, TaskResult


class GeminiTaskBase(Task):
    """
    Gemini ä»»åŠ¡åŸºç±»

    æä¾› Gemini API ç›¸å…³çš„é€šç”¨åŠŸèƒ½ï¼š
    - API å®¢æˆ·ç«¯ç®¡ç†
    - é‡è¯•æœºåˆ¶
    - å›¾ç‰‡éªŒè¯
    """

    def __init__(self, task_name: str, api_key: str, max_retries: int = 3):
        """
        åˆå§‹åŒ– Gemini ä»»åŠ¡

        Args:
            task_name: ä»»åŠ¡åç§°
            api_key: Gemini API Key
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        """
        super().__init__(task_name)
        self.api_key = api_key
        self.max_retries = max_retries
        self.retry_count = 0
        self.api_client: GeminiAPI = None

    def prepare(self) -> bool:
        """å‡†å¤‡ API å®¢æˆ·ç«¯"""
        try:
            # éªŒè¯ API Key
            if not self.api_key or not self.api_key.strip():
                self.update_progress(0, "API Key æœªè®¾ç½®")
                return False
            # åˆ›å»º API å®¢æˆ·ç«¯
            self.api_client = GeminiAPI(self.api_key)
            self.update_progress(0, "API å®¢æˆ·ç«¯å·²å‡†å¤‡")
            return True
        except Exception as e:
            self.update_progress(0, f"å‡†å¤‡å¤±è´¥: {str(e)}")
            return False

    def cleanup(self) -> None:
        """æ¸…ç†èµ„æº"""
        self.api_client = None

    def _validate_image_path(self, image_path: str, param_name: str = "å›¾ç‰‡") -> bool:
        """
        éªŒè¯å›¾ç‰‡è·¯å¾„

        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            param_name: å‚æ•°åç§°ï¼ˆç”¨äºé”™è¯¯æç¤ºï¼‰

        Returns:
            æ˜¯å¦æœ‰æ•ˆ
        """
        if not image_path:
            self.update_progress(message=f"{param_name}è·¯å¾„ä¸ºç©º")
            return False

        path = Path(image_path)
        if not path.exists():
            self.update_progress(message=f"{param_name}ä¸å­˜åœ¨: {image_path}")
            return False

        if not path.is_file():
            self.update_progress(message=f"{param_name}ä¸æ˜¯æ–‡ä»¶: {image_path}")
            return False

        # æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼ˆå¯é€‰ï¼‰
        file_size = path.stat().st_size
        max_size = 20 * 1024 * 1024  # 20MB
        if file_size > max_size:
            self.update_progress(message=f"{param_name}è¿‡å¤§: {file_size / 1024 / 1024:.1f}MB")
            return False
        return True


class GeminiImageGenerationTask(GeminiTaskBase):
    """
    Gemini å›¾ç‰‡ç”Ÿæˆä»»åŠ¡

    åŸºäºæ·±åº¦å›¾/å½©è‰²æ¸²æŸ“å›¾ + æç¤ºè¯ç”Ÿæˆæ–°å›¾ç‰‡
    """

    def __init__(
            self,
            api_key: str,
            image_path: str,
            user_prompt: str,
            reference_images_path: list[str],
            is_color_render: bool = False,
            width: int = 1024,
            height: int = 1024,
            aspect_ratio: str = "1:1",
            max_retries: int = 3,
    ):
        """
        åˆå§‹åŒ–å›¾ç‰‡ç”Ÿæˆä»»åŠ¡

        Args:
            api_key: Gemini API Key
            image_path: æ·±åº¦å›¾/è¾“å…¥å›¾ç‰‡è·¯å¾„
            user_prompt: ç”¨æˆ·æç¤ºè¯
            reference_images_path: å‚è€ƒå›¾ç‰‡è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            is_color_render: æ˜¯å¦ä¸ºå½©è‰²æ¸²æŸ“ï¼ˆTrue=å½©è‰², False=æ·±åº¦å›¾ï¼‰
            width: è¾“å‡ºå®½åº¦
            height: è¾“å‡ºé«˜åº¦
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        """
        super().__init__("Gemini å›¾ç‰‡ç”Ÿæˆ", api_key, max_retries)

        self.image_path = image_path
        self.user_prompt = user_prompt
        self.reference_images_path = reference_images_path
        self.is_color_render = is_color_render
        self.width = width
        self.height = height
        self.aspect_ratio = aspect_ratio

        # è®¾ç½®æ€»æ­¥éª¤æ•°
        self.progress.total_steps = 4

    def prepare(self) -> bool:
        """å‡†å¤‡ä»»åŠ¡"""
        if not super().prepare():
            return False

        # éªŒè¯è¾“å…¥å›¾ç‰‡
        if not self._validate_image_path(self.image_path, "è¾“å…¥å›¾ç‰‡"):
            return False

        # éªŒè¯å‚è€ƒå›¾ç‰‡ï¼ˆå¦‚æœæä¾›ï¼‰
        for ref_image_path in self.reference_images_path:
            if not self._validate_image_path(ref_image_path, "å‚è€ƒå›¾ç‰‡"):
                return False

        self.update_progress(1, "å‚æ•°éªŒè¯å®Œæˆ")
        return True

    def execute(self) -> TaskResult:
        """æ‰§è¡Œå›¾ç‰‡ç”Ÿæˆ"""
        try:
            time.sleep(1)
            if self.is_cancelled():
                error_msg = "ç”Ÿæˆå¤±è´¥: ä»»åŠ¡è¢«å–æ¶ˆ"
                self.update_progress(message=error_msg)
                return TaskResult.failure_result(Exception("ä»»åŠ¡è¢«å–æ¶ˆ"), error_msg)
            self.update_progress(2, "æ­£åœ¨è°ƒç”¨ Gemini API...")

            # è°ƒç”¨ API
            image_data, mime_type = b"", "image/png"
            image_data, mime_type = self.api_client.generate_image(
                depth_image_path=self.image_path,
                user_prompt=self.user_prompt,
                reference_images_path=self.reference_images_path,
                is_color_render=self.is_color_render,
                width=self.width,
                height=self.height,
                aspect_ratio=self.aspect_ratio,
            )

            if self.is_cancelled():
                error_msg = "ç”Ÿæˆå¤±è´¥: ä»»åŠ¡è¢«å–æ¶ˆ"
                self.update_progress(message=error_msg)
                return TaskResult.failure_result(Exception("ä»»åŠ¡è¢«å–æ¶ˆ"), error_msg)

            self.update_progress(3, "API è°ƒç”¨æˆåŠŸï¼Œå¤„ç†å“åº”...")

            # æ„å»ºç»“æœ
            result_data = {
                "image_data": image_data,
                "mime_type": mime_type,
                "width": self.width,
                "height": self.height,
            }

            if self.is_cancelled():
                error_msg = "ç”Ÿæˆå¤±è´¥: ä»»åŠ¡è¢«å–æ¶ˆ"
                self.update_progress(message=error_msg)
                return TaskResult.failure_result(Exception("ä»»åŠ¡è¢«å–æ¶ˆ"), error_msg)

            self.update_progress(4, "å›¾ç‰‡ç”Ÿæˆå®Œæˆ")

            return TaskResult.success_result(
                data=result_data,
                metadata={
                    "prompt": self.user_prompt,
                    "is_color_render": self.is_color_render,
                    "has_reference": bool(self.reference_images_path),
                },
            )

        except Exception as e:
            error_msg = f"å›¾ç‰‡ç”Ÿæˆå¤±è´¥: {str(e)}"
            self.update_progress(message=error_msg)
            return TaskResult.failure_result(e, error_msg)


class GeminiImageEditTask(GeminiTaskBase):
    """
    Gemini å›¾ç‰‡ç¼–è¾‘ä»»åŠ¡

    åŸºäºç°æœ‰å›¾ç‰‡ + æç¤ºè¯ + é®ç½©è¿›è¡Œç¼–è¾‘
    """

    def __init__(
            self,
            api_key: str,
            image_path: str,
            edit_prompt: str,
            mask_path: Optional[str] = None,
            reference_images_path: Optional[str] | list[str] = None,
            resolution: str = "1K",
            aspect_ratio: str = "1:1",
            max_retries: int = 3,
    ):
        """
        åˆå§‹åŒ–å›¾ç‰‡ç¼–è¾‘ä»»åŠ¡

        Args:
            api_key: Gemini API Key
            image_path: å¾…ç¼–è¾‘å›¾ç‰‡è·¯å¾„
            edit_prompt: ç¼–è¾‘æç¤ºè¯
            mask_path: é®ç½©å›¾ç‰‡è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            reference_images_path: å‚è€ƒå›¾ç‰‡è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            width: è¾“å‡ºå®½åº¦ï¼ˆ0=è‡ªåŠ¨ï¼‰
            height: è¾“å‡ºé«˜åº¦ï¼ˆ0=è‡ªåŠ¨ï¼‰
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        """
        super().__init__("Gemini å›¾ç‰‡ç¼–è¾‘", api_key, max_retries)

        self.image_path = image_path
        self.edit_prompt = edit_prompt
        self.mask_path = mask_path
        self.reference_images_path = reference_images_path
        self.resolution = resolution
        self.aspect_ratio = aspect_ratio

        self.progress.total_steps = 4

    def prepare(self) -> bool:
        """å‡†å¤‡ä»»åŠ¡"""
        if not super().prepare():
            return False

        # éªŒè¯è¾“å…¥å›¾ç‰‡
        if not self._validate_image_path(self.image_path, "å¾…ç¼–è¾‘å›¾ç‰‡"):
            return False

        # éªŒè¯é®ç½©ï¼ˆå¦‚æœæä¾›ï¼‰
        if self.mask_path:
            if not self._validate_image_path(self.mask_path, "é®ç½©å›¾ç‰‡"):
                return False

        # éªŒè¯å‚è€ƒå›¾ç‰‡ï¼ˆå¦‚æœæä¾›ï¼‰
        if self.reference_images_path:
            if isinstance(self.reference_images_path, list):
                for path in self.reference_images_path:
                    if not self._validate_image_path(path, "å‚è€ƒå›¾ç‰‡"):
                        return False
            else:
                if not self._validate_image_path(self.reference_images_path, "å‚è€ƒå›¾ç‰‡"):
                    return False

        self.update_progress(1, "å‚æ•°éªŒè¯å®Œæˆ")
        return True

    def execute(self) -> TaskResult:
        """æ‰§è¡Œå›¾ç‰‡ç¼–è¾‘"""
        try:
            self.update_progress(2, "æ­£åœ¨è°ƒç”¨ Gemini API...")

            # è°ƒç”¨ API
            image_data, mime_type = self.api_client.edit_image(
                image_path=self.image_path,
                edit_prompt=self.edit_prompt,
                mask_path=self.mask_path,
                reference_image_path=self.reference_images_path,
                resolution=self.resolution,
                aspect_ratio=self.aspect_ratio,
            )

            self.update_progress(3, "API è°ƒç”¨æˆåŠŸï¼Œå¤„ç†å“åº”...")

            # æ„å»ºç»“æœ
            result_data = {
                "image_data": image_data,
                "mime_type": mime_type,
            }

            self.update_progress(4, "å›¾ç‰‡ç¼–è¾‘å®Œæˆ")

            return TaskResult.success_result(
                data=result_data,
                metadata={
                    "prompt": self.edit_prompt,
                    "has_mask": bool(self.mask_path),
                    "has_reference": bool(self.reference_images_path),
                },
            )

        except Exception as e:
            error_msg = f"å›¾ç‰‡ç¼–è¾‘å¤±è´¥: {str(e)}"
            self.update_progress(message=error_msg)
            return TaskResult.failure_result(e, error_msg)


class GeminiStyleTransferTask(GeminiTaskBase):
    """
    Gemini é£æ ¼è¿ç§»ä»»åŠ¡

    å°†å‚è€ƒå›¾ç‰‡çš„é£æ ¼åº”ç”¨åˆ°ç›®æ ‡å›¾ç‰‡ä¸Š
    """

    def __init__(
            self,
            api_key: str,
            target_image_path: str,
            style_image_path: str,
            style_prompt: str = "",
            resolution="1K",
            aspect_ratio="1:1",
            max_retries: int = 3,
    ):
        """
        åˆå§‹åŒ–é£æ ¼è¿ç§»ä»»åŠ¡

        Args:
            api_key: Gemini API Key
            target_image_path: ç›®æ ‡å›¾ç‰‡è·¯å¾„
            style_image_path: é£æ ¼å‚è€ƒå›¾ç‰‡è·¯å¾„
            style_prompt: é£æ ¼æè¿°æç¤ºè¯ï¼ˆå¯é€‰ï¼‰
            width: è¾“å‡ºå®½åº¦ï¼ˆ0=è‡ªåŠ¨ï¼‰
            height: è¾“å‡ºé«˜åº¦ï¼ˆ0=è‡ªåŠ¨ï¼‰
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        """
        super().__init__("Gemini é£æ ¼è¿ç§»", api_key, max_retries)

        self.target_image_path = target_image_path
        self.style_image_path = style_image_path
        self.style_prompt = style_prompt
        self.resolution = resolution
        self.aspect_ratio = aspect_ratio
        self.progress.total_steps = 4

    def prepare(self) -> bool:
        """å‡†å¤‡ä»»åŠ¡"""
        if not super().prepare():
            return False

        # éªŒè¯ç›®æ ‡å›¾ç‰‡
        if not self._validate_image_path(self.target_image_path, "ç›®æ ‡å›¾ç‰‡"):
            return False

        # éªŒè¯é£æ ¼å›¾ç‰‡
        if not self._validate_image_path(self.style_image_path, "é£æ ¼å›¾ç‰‡"):
            return False

        self.update_progress(1, "å‚æ•°éªŒè¯å®Œæˆ")
        return True

    def execute(self) -> TaskResult:
        """æ‰§è¡Œé£æ ¼è¿ç§»"""
        try:
            self.update_progress(2, "æ­£åœ¨è°ƒç”¨ Gemini API...")

            # ä½¿ç”¨ edit_image æ–¹æ³•å®ç°é£æ ¼è¿ç§»
            image_data, mime_type = self.api_client.edit_image(
                image_path=self.target_image_path,
                edit_prompt=self.style_prompt or "åº”ç”¨å‚è€ƒå›¾ç‰‡çš„é£æ ¼",
                reference_image_path=self.style_image_path,
                resolution=self.resolution,
                aspect_ratio=self.aspect_ratio,
            )

            self.update_progress(3, "API è°ƒç”¨æˆåŠŸï¼Œå¤„ç†å“åº”...")

            # æ„å»ºç»“æœ
            result_data = {
                "image_data": image_data,
                "mime_type": mime_type,
            }

            self.update_progress(4, "é£æ ¼è¿ç§»å®Œæˆ")

            return TaskResult.success_result(
                data=result_data,
                metadata={
                    "style_prompt": self.style_prompt,
                },
            )

        except Exception as e:
            error_msg = f"é£æ ¼è¿ç§»å¤±è´¥: {str(e)}"
            self.update_progress(message=error_msg)
            return TaskResult.failure_result(e, error_msg)


###############################################################################
#         Reference: https://github.com/kovname/nano-banana-render            #
###############################################################################


class GeminiAPIError(Exception):
    pass


class GeminiAPI:
    def __init__(self, api_key: str, model="models/gemini-3-pro-image-preview"):
        self.api_key = api_key
        self.base_url = "https://generativelanguage.googleapis.com/v1beta"
        self.model = model

    def _build_generate_prompt(
            self,
            user_prompt: str,
            has_reference: bool = False,
            is_color_render: bool = False,
    ) -> str:
        if is_color_render:
            if has_reference:
                base_prompt = (
                    "You are receiving TWO images:\n\n"
                    "IMAGE 1 (3D Render - YOUR STRUCTURE SOURCE):\n"
                    "- This is the GEOMETRY and LAYOUT you must preserve\n"
                    "- Use this EXCLUSIVELY for object positions and composition\n"
                    "- IGNORE its bad materials and lighting\n"
                    "- This defines WHAT is in the scene\n\n"
                    "IMAGE 2 (Style Reference - YOUR VISUAL GUIDE):\n"
                    "- This is the STYLE source (materials, lighting, colors)\n"
                    "- DO NOT copy objects from here, only their 'look'\n"
                    "- Apply this style to the geometry of IMAGE 1\n"
                    "- This defines HOW the scene looks\n\n"
                    "USER PROMPT (THE SUPREME COMMAND):\n"
                    "- The User Prompt below OVERRIDES everything else for CONTENT decisions.\n"
                    "- If user says 'black background', MAKE IT BLACK, even if Reference Image has a detailed background.\n"
                    "- If user says 'add neon lights', ADD THEM, even if Reference Image is dark.\n"
                    "- Reference Image is for STYLE (how things look), User Prompt is for CONTENT (what things are).\n"
                    "- CONFLICT RESOLUTION: User Prompt > Reference Image Style > Input Render\n\n"
                    "YOUR TASK - AGGRESSIVE TRANSFORMATION:\n"
                    "1. Keep ONLY the composition/layout from IMAGE 1 (Depth/Structure)\n"
                    "2. COMPLETELY REPLACE materials, lighting, colors with IMAGE 2's style (UNLESS User Prompt says otherwise)\n"
                    "3. Make materials look like IMAGE 2 (if metallic there â†’ metallic here)\n"
                    "4. Match IMAGE 2's lighting direction, intensity, and color temperature\n"
                    "5. Use IMAGE 2's color palette - forget IMAGE 1's colors\n"
                    "6. Replicate IMAGE 2's atmosphere, depth, and mood\n"
                    "7. Think: 'IMAGE 1 is the skeleton, IMAGE 2 is the skin'\n\n"
                    "CRITICAL - DON'T BE CONSERVATIVE:\n"
                    "- If IMAGE 1 is blue but IMAGE 2 is warm â†’ make it WARM\n"
                    "- If IMAGE 1 is flat but IMAGE 2 has depth â†’ add DEPTH\n"
                    "- If IMAGE 1 is simple but IMAGE 2 is detailed â†’ add DETAILS\n"
                    "- TRANSFORM aggressively, don't just 'improve' IMAGE 1\n"
                    "- STRICTLY FOLLOW IMAGE 1's GEOMETRY/LAYOUT. Do not add objects from IMAGE 2.\n"
                )
            else:
                base_prompt = (
                    "You are receiving a LOW-QUALITY 3D RENDER that needs COMPLETE VISUAL OVERHAUL:\n\n"
                    "INPUT IMAGE (ROUGH DRAFT ONLY):\n"
                    "- Amateur 3D render with placeholder materials and basic lighting\n"
                    "- Use ONLY for general composition and object positions\n"
                    "- Colors are WRONG, materials are FAKE, lighting is FLAT\n"
                    "- This is NOT the target quality - you must COMPLETELY rebuild it\n\n"
                    "YOUR MISSION - TOTAL TRANSFORMATION:\n"
                    "1. REPLACE all materials with photorealistic equivalents:\n"
                    "   - Metal â†’ realistic metal with proper reflections, anisotropy, scratches\n"
                    "   - Plastic â†’ varied surface finish, subtle color variation, wear\n"
                    "   - Wood â†’ visible grain, natural color variation, texture depth\n"
                    "   - Glass â†’ proper refraction, reflections, subtle imperfections\n"
                    "   - Fabric â†’ weave patterns, soft shadows, natural draping\n\n"
                    "2. REBUILD lighting from scratch:\n"
                    "   - Add professional 3-point lighting or natural light sources\n"
                    "   - Strong shadows with soft edges\n"
                    "   - Realistic reflections and bounce light\n"
                    "   - Ambient occlusion in corners and crevices\n"
                    "   - Color temperature variation (warm/cool balance)\n\n"
                    "3. REIMAGINE colors:\n"
                    "   - Input colors are just suggestions - make them BETTER\n"
                    "   - Add professional color grading\n"
                    "   - Harmonious palette with contrast\n"
                    "   - Natural color variation within surfaces\n\n"
                    "4. ADD depth and atmosphere:\n"
                    "   - Volumetric lighting effects (god rays, haze)\n"
                    "   - Atmospheric perspective (depth fog)\n"
                    "   - Particle effects if appropriate (dust, moisture)\n"
                    "   - Background depth and detail\n\n"
                    "5. ENHANCE with imperfections:\n"
                    "   - Surface scratches, dents, wear patterns\n"
                    "   - Fingerprints on smooth surfaces\n"
                    "   - Dust accumulation in corners\n"
                    "   - Natural aging and weathering\n\n"
                    "USER PROMPT (THE SUPREME COMMAND):\n"
                    "- The User Prompt below is your PRIMARY INSTRUCTION for the transformation.\n"
                    "- If user says 'make it cyberpunk', use cyberpunk materials/lighting.\n"
                    "- If user says 'add rain', add rain.\n"
                    "- The input render provides the COMPOSITION, the User Prompt provides the STYLE/CONTENT.\n\n"
                    "CRITICAL MINDSET:\n"
                    "- Think: 'This is a SKETCH, not the final image'\n"
                    "- Your goal: 'Student work' â†’ 'Professional portfolio piece'\n"
                    "- Be BOLD with changes - the input is intentionally low quality\n"
                    "- Don't preserve bad materials or flat lighting\n"
                    "- Make every surface, light, and color DRAMATICALLY better\n"
                    "- Aim for: movie VFX quality or high-end product photography\n"
                )
        else:
            if has_reference:
                base_prompt = (
                    "You are receiving TWO images with different purposes:\n\n"
                    "IMAGE 1 (Style Reference):\n"
                    "- Use ONLY for: color palette, material textures, lighting mood, surface details\n"
                    "- DO NOT copy: composition, object placement, camera angle\n"
                    "- Extract: visual aesthetics, aspect ratio\n\n"
                    "IMAGE 2 (Depth Map):\n"
                    "- Black and white gradient representing depth\n"
                    "- White = closest objects, Black = farthest objects\n"
                    "- Use for: scene composition, object placement, 3D structure\n"
                    "- This depth map shows the spatial layout\n\n"
                    "YOUR TASK:\n"
                    "1. Understand 3D scene structure from depth map (IMAGE 2)\n"
                    "2. Apply visual style from reference (IMAGE 1) to that structure\n"
                    "3. Create photorealistic render combining: reference style + depth map geometry\n"
                    "4. Match aspect ratio of reference image\n\n"
                    "USER PROMPT (THE SUPREME COMMAND):\n"
                    "- The User Prompt below OVERRIDES everything else for CONTENT decisions.\n"
                    "- If user says 'make it red', MAKE IT RED, even if Reference is blue.\n"
                    "- Reference Image is for STYLE only. User Prompt is for CONTENT.\n"
                    "- CONFLICT RESOLUTION: User Prompt > Reference Image Style > Depth Map\n"
                )
            else:
                base_prompt = (
                    "You are receiving a DEPTH MAP image:\n\n"
                    "DEPTH MAP:\n"
                    "- Black and white gradient representing depth\n"
                    "- White = closest objects, Black = farthest objects\n"
                    "- Shows spatial relationships and 3D structure\n\n"
                    "YOUR TASK:\n"
                    "1. Interpret the depth map to understand scene geometry\n"
                    "2. Generate photorealistic 3D render based on this structure\n"
                    "3. Choose appropriate materials, colors, and lighting\n\n"
                    "USER PROMPT (THE SUPREME COMMAND):\n"
                    "- The User Prompt below is your PRIMARY INSTRUCTION.\n"
                    "- You MUST follow the user's description for materials, colors, and lighting.\n"
                    "- The Depth Map provides the SHAPE, the User Prompt provides the LOOK.\n"
                )
        if user_prompt.strip():
            return f"{base_prompt}\n\nUSER PROMPT (EXECUTE THIS): {user_prompt.strip()}"
        return base_prompt

    def generate_image(
            self,
            depth_image_path: str,
            user_prompt: str,
            reference_images_path: list[str],
            is_color_render: bool = False,
            width: int = 1024,
            height: int = 1024,
            aspect_ratio: str = "1:1",
    ) -> Tuple[bytes, str]:
        """
        ç”±æ·±åº¦å›¾å’Œæç¤ºè¯ç”Ÿæˆå›¾åƒ(å¯é€‰ä½¿ç”¨å‚è€ƒå›¾ä½œä¸º é£æ ¼åŒ–/æè´¨)
        Args:
            is_color_render: ä¸ºTrueå³ä½¿ç”¨å¸¸è§„eeveeæ¸²æŸ“, Falseä»£è¡¨ä½¿ç”¨æ·±åº¦å›¾(mist)
            width, height: è¾“å‡ºåˆ†è¾¨ç‡
        Returns: (image_data, format)
        """
        try:
            # æ„å»ºå®Œæ•´æç¤ºè¯
            full_prompt = self._build_generate_prompt(
                user_prompt,
                has_reference=bool(reference_images_path),
                is_color_render=is_color_render,
            )

            # æ§åˆ¶è¾“å‡ºåˆ†è¾¨ç‡
            full_prompt += f"\n\nCRITICAL OUTPUT SETTING: Generate image EXACTLY at {width}x{height} pixels."

            url = f"{self.base_url}/{self.model}:generateContent"
            headers = {
                "x-goog-api-key": self.api_key,
                "Content-Type": "application/json",
                "X-Goog-Api-Client": "python-blender-addon",
            }

            # Build parts array
            with open(depth_image_path, "rb") as f:
                image_base64 = base64.b64encode(f.read()).decode("utf-8")
            parts = [{"text": full_prompt}]
            part = {"inline_data": {"mime_type": "image/png", "data": image_base64}}
            parts.append(part)

            # Add reference image (Style) - SECOND image
            for reference_image_path in reference_images_path:
                with open(reference_image_path, "rb") as f:
                    reference_base64 = base64.b64encode(f.read()).decode("utf-8")
                part = {"inline_data": {"mime_type": "image/png", "data": reference_base64}}
                parts.append(part)

            # Map resolution to string format expected by API
            resolution_str = "1K"
            if width >= 4096 or height >= 4096:
                resolution_str = "4K"
            elif width >= 2048 or height >= 2048:
                resolution_str = "2K"

            payload = {
                "contents": [{"parts": parts}],
                "generationConfig": {
                    "temperature": 0.8,
                    "maxOutputTokens": 32768,
                    "candidateCount": 1,
                    "responseModalities": ["IMAGE"],
                    "imageConfig": {
                        "imageSize": resolution_str,
                        "aspectRatio": aspect_ratio,
                    },
                },
            }

            response = requests.post(url, headers=headers, json=payload, timeout=300)
            self._check_response_status(response)
            return self._parse_image_data_from_response_json(response.json())
        except requests.RequestException as e:
            raise GeminiAPIError(f"Network error: {str(e)}")
        except json.JSONDecodeError:
            raise GeminiAPIError("Failed to parse API response")
        except Exception as e:
            if isinstance(e, GeminiAPIError):
                raise
            raise GeminiAPIError(f"Unexpected error: {str(e)}")

    def _check_response_status(self, resp: requests.Response):
        code = resp.status_code
        if code == 403:
            raise GeminiAPIError("API key invalid or quota exceeded. Check your Google AI Studio account.")
        elif code == 429:
            retry_after = resp.headers.get("Retry-After", "unknown")
            raise GeminiAPIError(f"Rate limit exceeded. Retry after: {retry_after} seconds.")
        elif code == 400:
            raise GeminiAPIError(f"Bad request (400): {resp.text}")
        elif code != 200:
            raise GeminiAPIError(f"API request failed with status {code}: {resp.text}")

    def _parse_image_data_from_response_json(self, response_json: dict) -> Tuple[bytes, str]:
        if "candidates" not in response_json or not response_json["candidates"]:
            raise GeminiAPIError("No image generated. The model may have rejected the request.")

        candidate = response_json["candidates"][0]

        if "content" not in candidate:
            raise GeminiAPIError("Invalid response format - no content in candidate")

        parts: list[dict] = candidate["content"]["parts"]

        # æŸ¥æ‰¾å›¾ç‰‡æ•°æ®
        for part in parts:
            inline_data_key = None
            if "inline_data" in part:
                inline_data_key = "inline_data"
            elif "inlineData" in part:
                inline_data_key = "inlineData"

            if not inline_data_key:
                continue
            inline_data: dict = part[inline_data_key]

            data_key = None
            if "data" in inline_data:
                data_key = "data"
            elif "bytes" in inline_data:
                data_key = "bytes"

            if not data_key:
                continue

            if not inline_data[data_key]:
                continue
            mime_type = inline_data.get("mime_type", inline_data.get("mimeType", "image/jpeg"))
            image_data = base64.b64decode(inline_data[data_key])
            return image_data, mime_type

        # æ— å›¾æ—¶ï¼Œè¿”å›å ä½ç¬¦å›¾ç‰‡
        text_parts = [part.get("text", "") for part in parts]
        if any(text_parts):
            return self._create_placeholder_image()
        raise GeminiAPIError("No image data found in API response")

    def _create_placeholder_image(self) -> Tuple[bytes, str]:
        try:
            width, height = 100, 100
            png_data = self._create_empty_image(width, height, (0, 100, 200))
            return png_data, "image/png"
        except Exception as e:
            raise GeminiAPIError(f"Failed to create placeholder: {str(e)}")

    @staticmethod
    def _create_empty_image(width: int, height: int, color: tuple) -> bytes:
        with tempfile.NamedTemporaryFile(suffix=".png") as f:
            spec = oiio.ImageSpec(width, height, len(color), oiio.UINT8)
            out = oiio.ImageOutput.create(f.name)
            if not out:
                raise Exception(f"Could not create ImageOutput for {f.name}")
            pixels = np.full((height, width, len(color)), color, dtype=np.uint8)
            out.open(f.name, spec)
            out.write_image(pixels)
            out.close()
            png_data = Path(f.name).read_bytes()
            return png_data

    def edit_image(
            self,
            image_path: str,
            edit_prompt: str,
            mask_path: str = None,
            reference_image_path: str = None,
            resolution: str = "1K",
            aspect_ratio: str = "1:1",
    ) -> Tuple[bytes, str]:
        """
        åŸºäºæç¤ºè¯(å’Œé®ç½©, å¯é€‰)ç¼–è¾‘ç°æœ‰å›¾åƒ

        Args:
            image_path: ç¼–è¾‘è¾“å…¥å›¾åƒ
            edit_prompt: ç¼–è¾‘æç¤ºè¯
            mask_path: é®ç½©å›¾åƒ(å¯é€‰) white = edit, black = keep
            reference_image_path: é£æ ¼å‚è€ƒå›¾(å¯é€‰)
            width, height: ç›®æ ‡åˆ†è¾¨ç‡(å¯é€‰) 0ä¸ºè‡ªåŠ¨åŒ¹é…è¾“å…¥

        Returns: (image_data, mime_type)
        :param aspect_ratio:
        :param image_path:
        :param edit_prompt:
        :param mask_path:
        :param reference_image_path:
        :param resolution:
        """
        try:
            # Build edit prompt
            full_prompt = self._build_edit_prompt(
                edit_prompt,
                has_mask=bool(mask_path),
                has_reference=bool(reference_image_path),
            )
            return self._edit_with_rest(image_path, full_prompt, mask_path, reference_image_path, resolution,
                                        aspect_ratio)

        except Exception as e:
            if isinstance(e, GeminiAPIError):
                raise
            raise GeminiAPIError(f"Image edit failed: {str(e)}")

    def _build_edit_prompt(self, user_prompt: str, has_mask: bool = False, has_reference: bool = False) -> str:
        """Build prompt for image editing
        åŸºç¡€æç¤ºè¯ + ç”¨æˆ·è¾“å…¥æç¤ºè¯
        IMAGE 1 (scene with sketch)
        IMAGE 2 (mask - colored area)
        IMAGE OTHER (reference)
        """

        if user_prompt == "[FINALIZE_COMPOSITE]":  # æœ€ç»ˆåˆæˆçš„æç¤ºè¯
            base_prompt = (
                "COMPOSITE FINALIZATION - Unify entire image into seamless photorealistic result:\n\n"
                "CRITICAL CONTEXT:\n"
                "This image was created through multiple compositing steps (adding objects, inpainting, etc.).\n"
                "Your task: Make it look like ONE UNIFIED PHOTOGRAPH, not a collage.\n"
                "Remove ALL visible seams, color mismatches, lighting inconsistencies.\n\n"
                "COMMON PROBLEMS TO FIX:\n"
                "1. Objects have different color temperatures (some warm, some cool)\n"
                "2. Brightness mismatches between added objects and original scene\n"
                "3. Contrast differences (some areas too contrasty, others too flat)\n"
                "4. Shadow inconsistencies (direction or hardness doesn't match)\n"
                "5. Visible compositing edges or halos around objects\n"
                "6. Objects don't feel grounded in the scene\n"
                "7. Overall image lacks cohesion - looks like separate pieces\n\n"
                "YOUR TASK - PROFESSIONAL COLOR GRADING & UNIFICATION:\n"
                "STEP 1 - ANALYZE ENTIRE COMPOSITION:\n"
                "- Identify which areas look 'off' or disconnected\n"
                "- Find color temperature conflicts\n"
                "- Detect brightness/contrast mismatches\n"
                "- Look for unnatural edges or transitions\n\n"
                "STEP 2 - UNIFIED LIGHTING:\n"
                "- Establish ONE dominant light direction for entire scene\n"
                "- Make ALL objects respect this light direction\n"
                "- Unify shadow hardness across all elements\n"
                "- Add missing ambient occlusion between objects\n"
                "- Strengthen contact shadows where objects meet surfaces\n\n"
                "STEP 3 - COLOR HARMONY:\n"
                "- Choose ONE color temperature for the entire scene\n"
                "- Grade ALL objects to match this temperature\n"
                "- Create unified color palette - no outliers\n"
                "- Add subtle color spill between neighboring elements\n"
                "- Match saturation levels across all objects\n\n"
                "STEP 4 - CONTRAST & EXPOSURE:\n"
                "- Unify exposure - no objects too bright or too dark\n"
                "- Match contrast levels between all elements\n"
                "- Balance highlights and shadows across scene\n"
                "- Create cohesive tonal range\n\n"
                "STEP 5 - SEAMLESS INTEGRATION:\n"
                "- Blend ALL visible compositing edges\n"
                "- Remove halos, color fringing, or artifacts\n"
                "- Add atmospheric perspective if needed (distant = hazier)\n"
                "- Unify sharpness/blur across scene\n"
                "- Add subtle film grain or noise uniformly\n\n"
                "STEP 6 - GROUNDING & REALISM:\n"
                "- Ensure all objects cast appropriate shadows\n"
                "- Add reflections where needed (floors, mirrors, glossy surfaces)\n"
                "- Create subtle light bounce between objects\n"
                "- Add depth cues (foreground sharper, background softer)\n"
                "- Make everything feel 'heavy' and physically present\n\n"
                "REAL-WORLD EXAMPLE:\n"
                "BEFORE: Room with added furniture - chair too warm, table too bright, \n"
                "        plant has harsh shadows while room has soft shadows, visible edge around lamp\n"
                "AFTER FINALIZATION:\n"
                "  â†’ ALL objects color-graded to match room's cool daylight\n"
                "  â†’ Chair brightness reduced to match room exposure\n"
                "  â†’ ALL shadows softened to match ambient lighting\n"
                "  â†’ Lamp edge blended perfectly\n"
                "  â†’ Added contact shadows under all furniture\n"
                "  â†’ Slight color spill from wooden floor onto chair legs\n"
                "  â†’ Unified film grain over entire image\n"
                "  â†’ Result: Looks like ONE photograph, not composite\n\n"
                "CRITICAL SUCCESS CRITERIA:\n"
                "âœ… Image looks like ONE unified photograph\n"
                "âœ… ALL objects respect same lighting direction\n"
                "âœ… Consistent color temperature throughout\n"
                "âœ… Matched contrast and exposure across all elements\n"
                "âœ… NO visible compositing edges or seams\n"
                "âœ… Shadows are consistent (direction, hardness, color)\n"
                "âœ… Every object feels grounded and physically present\n"
                "âœ… Overall color harmony - no jarring mismatches\n"
                "âœ… Professional photorealistic result\n"
                "CRITICAL RULES:\n"
                "âŒ NEVER leave color temperature conflicts\n"
                "âŒ NEVER ignore exposure mismatches\n"
                "âŒ NEVER skip shadow unification\n"
                "âŒ NEVER leave visible compositing edges\n"
                "âŒ NEVER keep objects that look 'pasted on'\n"
                "âŒ NEVER leave lighting direction conflicts\n\n"
                "REMEMBER:\n"
                "You are a PROFESSIONAL COLORIST doing final grade.\n"
                "This is the LAST STEP before client delivery.\n"
                "Make it PERFECT - unified, seamless, photorealistic.\n"
                "Goal: Viewer should NEVER suspect this was composited.\n"
            )
            return base_prompt

        if has_mask and has_reference:  # æœ‰é®ç½©å’Œå‚è€ƒå›¾ç‰‡
            base_prompt = (
                "ğŸ¯ CRITICAL: READ USER'S PROMPT FIRST!\n"
                "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
                f"USER'S INSTRUCTION (DO THIS EXACTLY!):\n"
                f'"{user_prompt}"\n'
                "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
                "YOUR TASK - SIMPLE AND DIRECT:\n"
                "1. Read user's prompt above - THIS IS WHAT YOU MUST DO!\n"
                "2. Look at IMAGE 1 (scene with sketch) - ERASE the sketch\n"
                "3. Look at IMAGE 2 (mask - colored area) - this is WHERE to place it\n"
                "4. Look at IMAGE OTHER (reference) - find the object user wants\n"
                "5. Place object from IMAGE OTHER into the colored area from IMAGE 1\n"
                "6. Follow user's prompt for HOW to place it (sitting/standing/facing/etc)\n"
                "7. Relight object to match scene lighting\n\n"
                "WHAT YOU HAVE:\n"
                "â€¢ IMAGE 1 (SCENE) = Where to add it (has colored sketch showing location)\n"
                "â€¢ IMAGE 2 (MASK) = Exact colored area for placement\n"
                "â€¢ IMAGES OTHER (REFERENCE) = The object user wants to add\n"
                "â€¢ USER PROMPT = Tells you WHAT and HOW\n\n"
                "CRITICAL RULES:\n"
                " RULE #1: USER'S PROMPT IS LAW - Follow it EXACTLY!\n"
                " RULE #2: Place object in colored area from IMAGE 2 (mask)\n"
                " RULE #3: ERASE sketch completely - replace with real object\n"
                " RULE #4: Relight object to match IMAGE 1 lighting\n\n"
                "SIMPLE EXAMPLE:\n"
                "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
                "USER PROMPT: 'Ğ´Ğ¾Ğ±Ğ°Ğ²ÑŒ Ğ¼ÑƒĞ¶Ñ‡Ğ¸Ğ½Ñƒ Ğ½Ğ° Ñ‚Ñ€Ğ°Ğ²Ğµ Ğ² Ğ¾Ğ±Ğ²ĞµĞ´Ñ‘Ğ½Ğ½Ğ¾Ğ¼ ĞºÑ€ÑƒĞ³Ñƒ'\n"
                "\n"
                "WHAT YOU DO:\n"
                "1. Look at IMAGE 1 â†’ find the man\n"
                "2. Look at IMAGE 3 â†’ see the colored circle on grass\n"
                "3. Look at IMAGE 2 â†’ see the sketch circle (erase it!)\n"
                "4. Place man from IMAGE 1 into circle area\n"
                "5. Make him ON THE GRASS (user said 'Ğ½Ğ° Ñ‚Ñ€Ğ°Ğ²Ğµ')\n"
                "6. Erase colored circle sketch\n"
                "7. Relight man to match outdoor lighting\n"
                "8. Cast shadow on grass\n"
                "9. DONE - man is now on grass in that spot!\n"
                "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
                "HOW TO DO IT:\n"
                "STEP 1 - READ USER PROMPT (at the top!):\n"
                "  â†’ What object? (e.g., 'Ğ¼ÑƒĞ¶Ñ‡Ğ¸Ğ½Ñƒ', 'chair', 'car')\n"
                "  â†’ Where? (e.g., 'Ğ½Ğ° Ñ‚Ñ€Ğ°Ğ²Ğµ', 'at desk', 'in corner')\n"
                "  â†’ How? (e.g., 'standing', 'sitting', 'facing camera')\n\n"
                "STEP 2 - FIND OBJECT IN IMAGE 1:\n"
                "  â†’ Identify the object user wants\n"
                "  â†’ Remember its shape, textures, details\n"
                "  â†’ Ignore its background\n\n"
                "STEP 3 - FIND LOCATION:\n"
                "  â†’ IMAGE 2 (mask) shows colored area = exact spot\n"
                "  â†’ IMAGE 1 shows sketch = rough guide (erase it!)\n\n"
                "STEP 4 - PLACE OBJECT:\n"
                "  â†’ Put object in colored area (from IMAGE OTHER)\n"
                "  â†’ Follow user's prompt (orientation, pose, etc.)\n"
                "  â†’ ERASE sketch completely\n\n"
                "STEP 5 - MAKE IT REALISTIC:\n"
                "  â†’ Relight object to match IMAGE 1's lighting\n"
                "  â†’ Adjust colors to match scene\n"
                "  â†’ Cast shadows (direction must match scene)\n"
                "  â†’ Blend edges smoothly\n\n"
                "MORE EXAMPLES:\n"
                "Example 1 - 'ĞŸĞ¾ÑÑ‚Ğ°Ğ²ÑŒ ÑÑ‚Ğ¾Ñ‚ ÑÑ‚ÑƒĞ» Ğ² ÑƒĞ³Ğ»Ñƒ Ñƒ Ğ¾ĞºĞ½Ğ°':\n"
                "  â†’ Find chair in IMAGE OTHER\n"
                "  â†’ Place it in corner near window (colored area from IMAGE 1)\n"
                "  â†’ Erase colored sketch\n"
                "  â†’ Relight with window light\n"
                "  â†’ Cast shadow\n"
                "  â†’ DONE!\n\n"
                "Example 2 - 'Add this person sitting at the desk':\n"
                "  â†’ Find person in IMAGE OTHER\n"
                "  â†’ Place at desk (colored area)\n"
                "  â†’ Make them SITTING (user said so!)\n"
                "  â†’ Erase sketch\n"
                "  â†’ Relight with office lights\n"
                "  â†’ DONE!\n\n"
                "Example 3 - 'Ğ´Ğ¾Ğ±Ğ°Ğ²ÑŒ Ğ¼ÑƒĞ¶Ñ‡Ğ¸Ğ½Ñƒ Ğ½Ğ° Ñ‚Ñ€Ğ°Ğ²Ğµ Ğ² Ğ¾Ğ±Ğ²ĞµĞ´Ñ‘Ğ½Ğ½Ğ¾Ğ¼ ĞºÑ€ÑƒĞ³Ñƒ':\n"
                "  â†’ Find man in IMAGE OTHER\n"
                "  â†’ Place ON GRASS in circle area (IMAGE 1)\n"
                "  â†’ Erase circle sketch\n"
                "  â†’ Relight with outdoor lighting\n"
                "  â†’ Cast shadow on grass\n"
                "  â†’ DONE!\n\n"
                "WHAT YOU MUST DO:\n"
                "âœ… Follow user's prompt EXACTLY\n"
                "âœ… Place object in colored area (IMAGE 2)\n"
                "âœ… ERASE sketch completely\n"
                "âœ… Relight object to match scene\n"
                "âœ… Cast shadows\n"
                "âœ… Make it look photorealistic\n\n"
                "WHAT YOU MUST NOT DO:\n"
                "âŒ NEVER ignore user's prompt\n"
                "âŒ NEVER place object in wrong spot\n"
                "âŒ NEVER keep sketch visible\n"
                "âŒ NEVER forget shadows\n\n"
                "FINAL REMINDER:\n"
                "ğŸ”´ USER PROMPT (at top) = YOUR PRIMARY INSTRUCTION!\n"
                "ğŸ”´ Read it carefully and do EXACTLY what it says!\n"
            )
        elif has_mask:  # æœ‰é®ç½©
            base_prompt = (
                "INPAINTING TASK - Replace sketch with photorealistic content:\n\n"

                "CONTEXT:\n"
                "User drew a rough SKETCH on their image to show where they want NEW content.\n"
                "The sketch is UGLY and TEMPORARY - it's just a guide.\n"
                "Your job: ERASE the sketch, CREATE beautiful realistic content in that spot.\n\n"

                "IMAGE 1 (PHOTO WITH SKETCH OVERLAY):\n"
                "- Original photo/render with user's sketch drawn on top\n"
                "- Sketch colors show LOCATION and rough SHAPE only\n"
                "- Sketch is NOT the final look - it will be DELETED\n\n"

                "IMAGE 2 (MASK - WHERE TO EDIT):\n"
                "- Black areas = DON'T TOUCH (keep original)\n"
                "- Colored areas = SKETCH LOCATION (delete sketch, add new content)\n\n"

                "STEP-BY-STEP PROCESS:\n"
                "1. Look at IMAGE 1 - see the ugly sketch user drew\n"
                "2. Look at IMAGE 2 - see WHERE the sketch is\n"
                "3. Read user's PROMPT - understand WHAT to create\n"
                "4. COMPLETELY ERASE the sketch from those areas\n"
                "5. CREATE photorealistic content matching the prompt\n"
                "6. Match original image's lighting, shadows, perspective, style\n"
                "7. Blend edges perfectly (no visible seams)\n\n"

                "REAL EXAMPLES:\n"
                "Example 1:\n"
                "  - User draws RED CIRCLE\n"
                "  - Prompt: 'add sunset light through window'\n"
                "  - You do: DELETE red circle â†’ CREATE realistic warm sunlight rays\n"
                "  - Final: Beautiful sunset light, NO red circle visible\n\n"

                "Example 2:\n"
                "  - User draws BLUE BLOB\n"
                "  - Prompt: 'add water puddle on floor'\n"
                "  - You do: DELETE blue blob â†’ CREATE realistic water with reflections\n"
                "  - Final: Real water puddle, NO blue blob visible\n\n"

                "Example 3:\n"
                "  - User draws GREEN SCRIBBLES\n"
                "  - Prompt: 'add plant in vase'\n"
                "  - You do: DELETE green scribbles â†’ CREATE detailed plant with leaves\n"
                "  - Final: Beautiful plant, NO scribbles visible\n\n"

                "CRITICAL RULES:\n"
                "âŒ NEVER keep the sketch visible\n"
                "âŒ NEVER 'improve' the sketch - DELETE it completely\n"
                "âŒ NEVER leave construction lines, rough shapes, or color blobs\n"
                "âœ… ALWAYS erase sketch 100% before creating new content\n"
                "âœ… ALWAYS create photorealistic result\n"
                "âœ… ALWAYS match original image lighting and style\n"
                "âœ… ALWAYS blend seamlessly at edges\n"
                "âœ… ALWAYS follow user's text prompt for WHAT to create\n\n"

                "REMEMBER:\n"
                "Sketch = temporary guide (like construction lines in drawing)\n"
                "Final image = professional result with NO sketch traces\n"
                "User drew sketch to show LOCATION + rough IDEA\n"
                "You create PHOTOREALISTIC version and REMOVE sketch completely\n"
            )
        elif has_reference:  # æœ‰å‚è€ƒå›¾ç‰‡
            base_prompt = (
                "PHOTOREALISTIC OBJECT INTEGRATION - Seamlessly blend reference into scene:\n\n"
                "CRITICAL CONTEXT:\n"
                "User is NOT asking for simple copy-paste! They want PHOTOREALISTIC INTEGRATION.\n"
                "The object from reference must look like it was PHOTOGRAPHED in the target scene.\n"
                "This requires ADVANCED color grading, lighting match, shadow casting, and perspective correction.\n\n"
                "IMAGE 1 (TARGET SCENE - DESTINATION):\n"
                "- This is your PRIMARY reference for visual style\n"
                "- Analyze: lighting direction, color temperature, shadow hardness, ambient light\n"
                "- The object from IMAGE 1 must MATCH this scene's lighting 100%\n\n"
                "IMAGE OTHER (REFERENCE - SOURCE OBJECT):\n"
                "- Contains the object/person to integrate into IMAGE 1\n"
                "- Extract its SHAPE and STRUCTURE (what it is)\n"
                "- IGNORE its original lighting, colors, and background\n"
                "- Think: 'I need this OBJECT, but I'll RELIGHT it for the new scene'\n\n"
                "YOUR TASK - PROFESSIONAL COMPOSITING:\n"
                "STEP 1 - LIGHTING ANALYSIS (IMAGE 1):\n"
                "- Light direction: Where are shadows pointing? (e.g., left side, top-right)\n"
                "- Light hardness: Sharp shadows = hard light, soft shadows = diffuse light\n"
                "- Color temperature: Warm (orange/yellow) or cool (blue/white)?\n"
                "- Ambient light: How bright are shadow areas?\n"
                "- Reflections: Are there glossy surfaces? What do they reflect?\n\n"
                "STEP 2 - OBJECT EXTRACTION (IMAGE OTHER):\n"
                "- Identify the object shape, structure, materials\n"
                "- Forget its current lighting - you will RELIGHT it\n"
                "- Preserve textures and material properties (metal, wood, fabric, etc.)\n\n"
                "STEP 3 - INTEGRATION (CRITICAL!):\n"
                "A. RELIGHTING:\n"
                "   - Apply IMAGE 1's light direction to the object\n"
                "   - Match light color temperature exactly\n"
                "   - Create shadows that match IMAGE 1's shadow style\n"
                "   - Add ambient occlusion in contact areas\n"
                "B. COLOR GRADING:\n"
                "   - Adjust object's colors to match IMAGE 1's color palette\n"
                "   - If IMAGE 1 is warm â†’ warm the object's colors\n"
                "   - If IMAGE 1 is desaturated â†’ reduce object's saturation\n"
                "   - Match overall brightness/exposure\n"
                "C. SHADOWS:\n"
                "   - Cast shadows from object onto IMAGE 1's surfaces\n"
                "   - Shadow direction MUST match IMAGE 1's existing shadows\n"
                "   - Shadow softness MUST match IMAGE 1's shadow hardness\n"
                "   - Add contact shadows (dark areas where object touches surface)\n"
                "D. PERSPECTIVE:\n"
                "   - Match camera angle from IMAGE 1\n"
                "   - Scale object appropriately for scene\n"
                "   - Ensure ground plane alignment\n"
                "E. REFLECTIONS & AMBIENT:\n"
                "   - If object is glossy â†’ reflect IMAGE 1's environment\n"
                "   - Add ambient light bounce from IMAGE 1's surfaces\n"
                "   - Color spill: nearby colored surfaces affect object colors\n\n"
                "STEP 4 - FINAL BLEND:\n"
                "- Edge softness: match IMAGE 1's sharpness/blur\n"
                "- Atmospheric perspective: distant objects are hazier\n"
                "- Depth of field: match IMAGE 1's focus plane\n"
                "- Film grain/noise: match IMAGE 1's texture\n\n"
                "REAL-WORLD EXAMPLE:\n"
                "IMAGE 1: Dark moody interior with warm tungsten lights from left\n"
                "IMAGE 2: Photo of a red chair (photographed outdoors, bright daylight)\n"
                "USER: 'Add the chair by the window'\n"
                "WRONG (copy-paste): Bright red chair with daylight look = looks fake!\n"
                "RIGHT (professional integration):\n"
                "  â†’ Chair shape preserved\n"
                "  â†’ BUT relit with warm tungsten light from left\n"
                "  â†’ Red color adjusted to warm/darker tone matching room\n"
                "  â†’ Soft shadow cast to the right (opposite of light)\n"
                "  â†’ Contact shadow under chair legs (ambient occlusion)\n"
                "  â†’ Slight warm color spill from wooden floor onto chair base\n"
                "  â†’ Chair looks like it was PHOTOGRAPHED in this room\n\n"
                "CRITICAL SUCCESS CRITERIA:\n"
                "âœ… Object MUST look like it was PHOTOGRAPHED in IMAGE 1's scene\n"
                "âœ… Lighting on object MUST match IMAGE 1 exactly (direction, color, hardness)\n"
                "âœ… Object colors MUST be color-graded to match IMAGE 1's palette\n"
                "âœ… Shadows MUST be cast correctly with right direction and softness\n"
                "âœ… No visible compositing edges - perfect blend\n"
                "âœ… Viewer should NOT be able to tell it's from different photo\n"
                "CRITICAL MISTAKES TO AVOID:\n"
                "âŒ NEVER keep object's original lighting from IMAGE OTHER\n"
                "âŒ NEVER keep object's original colors unchanged\n"
                "âŒ NEVER forget to cast shadows onto IMAGE 1's surfaces\n"
                "âŒ NEVER ignore IMAGE 1's light direction\n"
                "âŒ NEVER make it look like a PNG sticker pasted on\n"
                "âŒ NEVER create lighting conflicts (e.g., shadows wrong direction)\n\n"
                "REMEMBER:\n"
                "You are a PROFESSIONAL COMPOSITOR, not a copy-paste tool.\n"
                "The object must be RELIT, COLOR-GRADED, and SHADOWED to match the target scene.\n"
                "Final result should be INDISTINGUISHABLE from a real photograph.\n"
                "OLD STYLE TRANSFER PROMPT (for reference, DON'T use this):\n"
                "You are receiving TWO images:\n\n"
                "IMAGE 1 (Original Image - ONLY for composition):\n"
                "- Use EXCLUSIVELY for object positions, layout, scene structure\n"
                "- IGNORE its colors, materials, lighting, and current style\n"
                "- Treat current look as TEMPORARY - will be completely replaced\n"
                "- Keep ONLY the composition, everything else changes\n\n"
                "IMAGE OTHER (Style Reference - YOUR PRIMARY GUIDE):\n"
                "- This is your MAIN reference for ALL visual aspects\n"
                "- COPY AGGRESSIVELY: lighting setup, material types, color palette, texture quality, mood, atmosphere\n"
                "- Study this image's visual language and REPLICATE it completely\n"
                "- This shows the TARGET result you must achieve\n\n"
                "YOUR TASK - AGGRESSIVE STYLE TRANSFORMATION:\n"
                "1. Keep ONLY composition/layout/objects from IMAGE 1\n"
                "2. COMPLETELY REPLACE materials with IMAGE OTHER style:\n"
                "   - If IMAGE OTHER has metallic materials â†’ make IMAGE 1's objects metallic\n"
                "   - If IMAGE OTHER has matte surfaces â†’ make IMAGE 1's objects matte\n"
                "   - If IMAGE OTHER has wood texture â†’ apply wood-like materials\n"
                "3. COMPLETELY REPLACE lighting with IMAGE OTHER setup:\n"
                "   - Match light direction, intensity, color temperature\n"
                "   - Copy shadow hardness/softness\n"
                "   - Replicate ambient lighting mood\n"
                "4. COMPLETELY REPLACE colors with IMAGE OTHER palette:\n"
                "   - If IMAGE OTHER is warm (orange/red) â†’ make IMAGE 1 warm\n"
                "   - If IMAGE OTHER is cool (blue/cyan) â†’ make IMAGE 1 cool\n"
                "   - Match color saturation and vibrancy\n"
                "5. REPLICATE atmosphere and mood:\n"
                "   - If IMAGE OTHER is dramatic â†’ make IMAGE 1 dramatic\n"
                "   - If IMAGE OTHER is soft/gentle â†’ make IMAGE 1 soft/gentle\n"
                "   - Copy depth, detail level, visual complexity\n\n"
                "CRITICAL - BE AGGRESSIVE, NOT CONSERVATIVE:\n"
                "âŒ DON'T just 'slightly adjust' IMAGE 1\n"
                "âŒ DON'T preserve IMAGE 1's current colors/materials\n"
                "âŒ DON'T be subtle or gentle with changes\n"
                "âœ… COMPLETELY TRANSFORM to match IMAGE OTHER style\n"
                "âœ… Think: 'IMAGE OTHER is the goal, IMAGE 1 is just a layout template'\n"
                "âœ… If IMAGE OTHER is blue but IMAGE 1 is red â†’ make it BLUE\n"
                "âœ… If IMAGE OTHER is dark but IMAGE 1 is bright â†’ make it DARK\n"
                "âœ… If IMAGE OTHER is detailed but IMAGE 1 is simple â†’ add DETAILS\n\n"
                "EXAMPLE:\n"
                "- IMAGE 1: Cool blue render with flat lighting\n"
                "- IMAGE OTHER: Warm sunset photo with golden light, soft shadows, rich textures\n"
                "- YOUR RESULT: Keep IMAGE 1's objects/layout BUT with:\n"
                "  â†’ Golden sunset lighting from IMAGE OTHER\n"
                "  â†’ Warm orange/red colors from IMAGE OTHER\n"
                "  â†’ Soft shadows and rich textures from IMAGE OTHER\n"
                "  â†’ Final looks like IMAGE OTHER style applied to IMAGE 1's composition\n\n"
                "REMEMBER:\n"
                "Original image (IMAGE 1) = composition template ONLY\n"
                "Style reference (IMAGE OTHER) = your visual TARGET\n"
                "AGGRESSIVELY copy IMAGE OTHER visual style to IMAGE 1's layout\n"
            )
        else:
            # æ²¡æœ‰é®ç½©ä¹Ÿæ²¡æœ‰å‚è€ƒå›¾ç‰‡,åªæœ‰æç¤ºè¯è¾“å…¥çš„åŸºæœ¬æç¤ºè¯
            base_prompt = (
                "You are REFINING and IMPROVING an existing image:\n\n"
                "ORIGINAL IMAGE:\n"
                "- This is the base image you'll improve\n"
                "- Keep main composition, subjects, layout\n\n"
                "YOUR TASK:\n"
                "1. Understand current image\n"
                "2. Apply user's improvement instructions\n"
                "3. Keep overall composition intact\n"
                "4. Make changes feel natural and cohesive\n"
                "5. Enhance quality while preserving intent\n"
            )
        if user_prompt.strip():
            return f"{base_prompt}\n\nUSER'S EDIT INSTRUCTIONS:\n{user_prompt.strip()}"
        else:
            return base_prompt

    def _edit_with_rest(
            self,
            image_path: str,
            prompt: str,
            mask_path: str = None,
            reference_path: str = None,
            resolution="1K",
            aspect_ratio: str = "1:1",
    ) -> Tuple[bytes, str]:
        """
        å›¾ç‰‡é¡ºåºå¾ˆé‡è¦
        IMAGE 1 (scene with sketch)
        IMAGE 2 (mask - colored area)
        IMAGE OTHER (reference)
        """
        try:
            parts = [{"text": prompt}]

            def add_part(image_file_path):
                with open(image_file_path, "rb") as f:
                    image_base64 = base64.b64encode(f.read()).decode("utf-8")
                part = {"inline_data": {"mime_type": "image/png", "data": image_base64}}
                parts.append(part)
                print("add_part", image_file_path)

            add_part(image_path)  # æ·»åŠ ä¸»å›¾
            # æ·»åŠ é®ç½©
            if mask_path:
                add_part(mask_path)
            if reference_path:
                if isinstance(reference_path, list):
                    for ref_path in reference_path:
                        add_part(ref_path)
                else:
                    add_part(reference_path)
            url = f"{self.base_url}/{self.model}:generateContent"
            headers = {
                "x-goog-api-key": self.api_key,
                "Content-Type": "application/json",
                "X-Goog-Api-Client": "python-blender-addon",
            }
            payload = {
                "contents": [{"parts": parts}],
                "generationConfig": {
                    "temperature": 0.7,  # Lower temperature for more faithful edits
                    "maxOutputTokens": 32768,
                    "candidateCount": 1,
                    "responseModalities": ["TEXT", "IMAGE"],
                    "imageConfig": {
                        "imageSize": resolution,
                        "aspectRatio": aspect_ratio,
                    },
                },
            }
            response = requests.post(url, headers=headers, json=payload, timeout=300)
            if response.status_code != 200:
                raise GeminiAPIError(f"Edit request failed: {response.status_code} - {response.text}")
            # Parse response (same as generate_with_rest)
            result = response.json()
            if "candidates" not in result or not result["candidates"]:
                raise GeminiAPIError("No candidates in edit response")
            parts = result["candidates"][0]["content"]["parts"]
            # Find image part
            for part in parts:
                inline_data_key = "inline_data" if "inline_data" in part else "inlineData" if "inlineData" in part else None
                if not inline_data_key:
                    continue
                inline_data = part[inline_data_key]
                data_key = "data" if "data" in inline_data else "bytes" if "bytes" in inline_data else None
                if data_key and inline_data[data_key]:
                    image_data = base64.b64decode(inline_data[data_key])
                    mime_type = inline_data.get("mime_type", inline_data.get("mimeType", "image/png"))
                    return image_data, mime_type
            raise GeminiAPIError("No image found in edit response")
        except requests.RequestException as e:
            raise GeminiAPIError(f"Network error during edit: {str(e)}")
        except Exception as e:
            if isinstance(e, GeminiAPIError):
                raise
            raise GeminiAPIError(f"Edit failed: {str(e)}")
